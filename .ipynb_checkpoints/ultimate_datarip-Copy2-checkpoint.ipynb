{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to patent db...\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "#sqlalchemy connection object\n",
    "print(\"Connecting to patent db...\")\n",
    "engine = create_engine('mysql+pymysql://ipmaster:oroonoko64@ipinformatics.ccmbmjzurfjl.us-west-1.rds.amazonaws.com:3306/ipinformatics')\n",
    "connection = engine.connect()\n",
    "print(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in patent IDs...\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "#read in patent ids\n",
    "with open(\"patent_ids_705_small.csv\", \"r\") as f:\n",
    "    print(\"Reading in patent IDs...\")\n",
    "    idlist = f.read().splitlines()\n",
    "    print(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks to do: 1\n",
      "Size of remainder: 22\n"
     ]
    }
   ],
   "source": [
    "#chunker\n",
    "chunks = []\n",
    "subchunk = []\n",
    "\n",
    "maxchunks = int(len(idlist)/5000)\n",
    "maxchunks_real = maxchunks + 1\n",
    "print(\"Total chunks to do: \" + str(maxchunks_real))\n",
    "\n",
    "remainder = len(idlist) - (maxchunks*5000)\n",
    "print(\"Size of remainder: \" + str(remainder))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for id in idlist:\n",
    "    subchunk.append(id)\n",
    "    if count <= maxchunks:\n",
    "        if len(subchunk) == 5000:\n",
    "            yy = ','.join(str(s) for s in subchunk)\n",
    "            chunks.append(yy)\n",
    "            count = count + 1\n",
    "            subchunk = []\n",
    "    elif count > maxchunks:\n",
    "        if len(subchunk) == remainder:\n",
    "            yy = ','.join(str(s) for s in subchunk)\n",
    "            chunks.append(yy)\n",
    "            count = count + 1\n",
    "            subchunk = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lookup Query Redux\n",
    "\n",
    "lookup = \"SELECT s_no as application_id, filing_date, patent_no, date as grant_date, organization as company FROM iplogic.pair_application INNER JOIN ipinformatics.patentsview_patent ON iplogic.pair_application.patent_no = ipinformatics.patentsview_patent.id INNER JOIN ipinformatics.patentsview_raw_assignee ON iplogic.pair_application.patent_no = ipinformatics.patentsview_raw_assignee.patent_id WHERE iplogic.pair_application.patent_no IN (\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "for c in chunks:\n",
    "    count = count + 1\n",
    "    print(\"Chunk No. \" + str(count))\n",
    "    \n",
    "    query = lookup + str(c) + \")\"\n",
    "    initial_frame = pd.read_sql_query(query, connection)\n",
    "    print(initial_frame.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial_frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f558a98d3baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlookup_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_frame\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'initial_frame' is not defined"
     ]
    }
   ],
   "source": [
    "#Lookup Query No. 1\n",
    "\n",
    "lookup = \"SELECT s_no as application_id, filing_date, patent_no, date as grant_date, organization as company FROM iplogic.pair_application INNER JOIN ipinformatics.patentsview_patent ON iplogic.pair_application.patent_no = ipinformatics.patentsview_patent.id INNER JOIN ipinformatics.patentsview_raw_assignee ON iplogic.pair_application.patent_no = ipinformatics.patentsview_raw_assignee.patent_id WHERE iplogic.pair_application.patent_no IN (\"\n",
    "\n",
    "count = 0\n",
    "#df1 = pd.DataFrame(index =['application_id'], columns = ['application_id', 'filing_date', 'patent_no', 'grant_date', 'company'])\n",
    "\n",
    "for c in chunks:\n",
    "    if count == 0:\n",
    "        count = count + 1\n",
    "        print(\"Chunk No. \" + str(count))\n",
    "        query = lookup + str(c) + \")\"\n",
    "        initial_frame = pd.read_sql_query(query, connection)\n",
    "        print(initial_frame.head())\n",
    "    else:\n",
    "        count = count + 1\n",
    "        print(\"Chunk No. \" + str(count))\n",
    "        query = lookup + str(c) + \")\"\n",
    "        lookup_frame = pd.read_sql_query(query, connection)\n",
    "        pd.concat([lookup_frame, initial_frame], axis=1)\n",
    "    \n",
    "print(initial_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['filing_date_y' 'patent_no_y' 'grant_date_y' 'company_y'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-1c217a977d7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filing_date_y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'patent_no_y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'grant_date_y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'company_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tylerseymour/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tylerseymour/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['filing_date_y' 'patent_no_y' 'grant_date_y' 'company_y'] not contained in axis"
     ]
    }
   ],
   "source": [
    "df.drop(['filing_date_y','patent_no_y','grant_date_y','company_y'], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookup_frame.to_json(\"lookup.json\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6337911', '6507279', '6480960']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Metadata Query No. 1\n",
    "metadata1 = \"SELECT patent_id, number AS application_number, date AS grant_date FROM ipinformatics.patentsview_application WHERE patent_id IN(\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "for c in chunks:\n",
    "    count = count + 1\n",
    "    print(\"Chunk No. \" + str(count))\n",
    "    query = metadata1 + str(c) + \")\"\n",
    "    md1 = pd.read_sql_query(query, connection)\n",
    "    md1.set_index('patent_id')\n",
    "\n",
    "print(md1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Metadata Query No. 2\n",
    "metadata2 = \"SELECT patent_id, assignee_id FROM ipinformatics.patentsview_patent_assignee WHERE patent_id IN(\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "for c in chunks:\n",
    "    count = count + 1\n",
    "    print(\"Chunk No. \" + str(count))\n",
    "    query = metadata2 + str(c) + \")\"\n",
    "    md2 = pd.read_sql_query(query, connection)\n",
    "    md2.set_index('patent_id')\n",
    "    \n",
    "md2['assignee_id'] = md2.assignee_id.str.replace(r'\\r', '')\n",
    "print(md2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Metadata Query No. 3\n",
    "metadata3 = \"SELECT patent_no AS patent_id, primary_examiner_name AS examiner_id, group_art_unit_no AS group_art_unit FROM iplogic.pair_application WHERE patent_no IN(\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "for c in chunks:\n",
    "    count = count + 1\n",
    "    print(\"Chunk No. \" + str(count))\n",
    "    query = metadata3 + str(c) + \")\"\n",
    "    md3 = pd.read_sql_query(query, connection)\n",
    "    md3.set_index('patent_id')\n",
    "\n",
    "print(md3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tech Class 1 - Query No. 4\n",
    "techclass1 = \"SELECT patent_id, mainclass_id AS uspc, sequence FROM ipinformatics.patentsview_uspc WHERE patent_id IN(\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "for c in chunks:\n",
    "    count = count + 1\n",
    "    print(\"Chunk No. \" + str(count))\n",
    "    query = techclass1 + str(c) + \")\"\n",
    "    tc1 = pd.read_sql_query(query, connection)\n",
    "    tc1.set_index('patent_id')\n",
    "\n",
    "print(tc1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tech Class 2 - Query No. 5\n",
    "\n",
    "techclass2 = \"SELECT patent_id, group_id AS cpc, sequence FROM ipinformatics.patentsview_cpc_current WHERE patent_id IN(\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "for c in chunks:\n",
    "    count = count + 1\n",
    "    print(\"Chunk No. \" + str(count))\n",
    "    query = techclass2 + str(c) + \")\"\n",
    "    tc2 = pd.read_sql_query(query, connection)\n",
    "    tc2.set_index('patent_id')\n",
    "\n",
    "print(tc2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Citations 1 - Query No. 6\n",
    "cites1 = \"SELECT patent_id, citation_id, date, category, sequence FROM ipinformatics.patentsview_us_patent_citation WHERE patent_id IN(\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "for c in chunks:\n",
    "    count = count + 1\n",
    "    print(\"Chunk No. \" + str(count))\n",
    "    query = cites1 + str(c) + \")\"\n",
    "    ct1 = pd.read_sql_query(query, connection)\n",
    "    ct1.set_index('patent_id')\n",
    "\n",
    "print(ct1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Claims 1 - Query No. 7\n",
    "\n",
    "#chunker\n",
    "chunks = []\n",
    "subchunk = []\n",
    "\n",
    "maxchunks = int(len(idlist)/5000)\n",
    "maxchunks_real = maxchunks + 1\n",
    "print(\"Total chunks to do: \" + str(maxchunks_real))\n",
    "\n",
    "remainder = len(idlist) - (maxchunks*5000)\n",
    "print(\"Size of remainder: \" + str(remainder))\n",
    "\n",
    "count = 0\n",
    "count2 = 0\n",
    "\n",
    "for id in idlist:\n",
    "    subchunk.append(id)\n",
    "    if count <= maxchunks:\n",
    "        if len(subchunk) == 5000:\n",
    "            yy = \"','\".join(str(s) for s in subchunk)\n",
    "            chunks.append(yy)\n",
    "            count = count + 1\n",
    "            subchunk = []\n",
    "    elif count > maxchunks:\n",
    "        if len(subchunk) == remainder:\n",
    "            yy = \"','\".join(str(s) for s in subchunk)\n",
    "            chunks.append(yy)\n",
    "            count = count + 1\n",
    "            subchunk = []\n",
    "claims1 = \"SELECT patent_id, text, sequence, dependent FROM ipinformatics.patentsview_claim WHERE patent_id IN('\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "for c in chunks:\n",
    "    count = count + 1\n",
    "    print(\"Chunk No. \" + str(count))\n",
    "    query = claims1 + str(c) + \"')\"\n",
    "    clm1 = pd.read_sql_query(query, connection)\n",
    "    clm1.set_index('patent_id')\n",
    "\n",
    "print(clm1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ultimate Merge\n",
    "merge1 = md1.merge(md2, on='patent_id', how='left')\n",
    "merge2 = merge1.merge(md3, on='patent_id', how='left')\n",
    "merge3 = merge2.merge(tc1, on='patent_id', how='left')\n",
    "finalmerge = merge3.merge(ct1, on='patent_id', how='left')\n",
    "\n",
    "print(finalmerge.head())\n",
    "print(\"Number of records for this query -->\")\n",
    "print(finalmerge.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Switching to new dataframe DF....\n",
    "df = finalmerge\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_json(\"ultrarip.json\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
